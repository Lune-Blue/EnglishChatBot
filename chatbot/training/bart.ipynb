{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!ls -al"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pwd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "--Preprosessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset(\"jfleg\", split='validation[:]')\n",
    "\n",
    "eval_dataset = load_dataset(\"jfleg\", split='test[:]')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset jfleg (/home/intern/.cache/huggingface/datasets/jfleg/default/1.0.0/165d64b6ad479919c1e2e24b0b4e8633d4ae76b335a477c6a4f89056eb5bcf07)\n",
      "Using custom data configuration default\n",
      "Reusing dataset jfleg (/home/intern/.cache/huggingface/datasets/jfleg/default/1.0.0/165d64b6ad479919c1e2e24b0b4e8633d4ae76b335a477c6a4f89056eb5bcf07)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import csv\n",
    "\n",
    "def generate_csv(csv_path, dataset):\n",
    "    with open(csv_path, 'w', newline='') as csvfile:\n",
    "        writter = csv.writer(csvfile)\n",
    "        writter.writerow([\"input\", \"target\"])\n",
    "        for case in dataset:\n",
    "     \t    # Adding the task's prefix to input \n",
    "            input_text = case[\"sentence\"]\n",
    "            for correction in case[\"corrections\"]:\n",
    "                # a few of the cases contain blank strings. \n",
    "                if input_text and correction:\n",
    "                    writter.writerow([input_text, correction])\n",
    "                    \n",
    "\n",
    "\n",
    "generate_csv(\"train.csv\", train_dataset)\n",
    "generate_csv(\"eval.csv\", eval_dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for case in train_dataset[\"corrections\"][:2]:\n",
    "    print(case)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "--testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "ARTICLE_TO_SUMMARIZE = \"My friends are cool but they eat too many carbs.\"\n",
    "inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors='pt')\n",
    "\n",
    "summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=5, early_stopping=True)\n",
    "print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import pandas as pd\n",
    "train_path = '/home/intern/seungjun/error_data/train.csv'\n",
    "test_path = '/home/intern/seungjun/error_data/eval.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_path, encoding='utf-8')\n",
    "test_data = pd.read_csv(test_path, encoding='utf-8')\n",
    "\n",
    "train_data.dropna(axis=0, inplace=True)\n",
    "test_data.dropna(axis=0, inplace=True)\n",
    "\n",
    "train_input = train_data['input'].tolist()\n",
    "train_label = train_data['target'].tolist()\n",
    "\n",
    "test_input = test_data['input'].tolist()\n",
    "test_label = test_data['target'].tolist()\n",
    "\n",
    "print(len(train_input))\n",
    "print(len(train_label))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3016\n",
      "3016\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "--BartConditionalGeneration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "train_inputs_tokenize = tokenizer(train_input, return_tensors='pt', padding=True)\n",
    "train_labels_tokenize = tokenizer(train_label, return_tensors='pt', padding=True)\n",
    "\n",
    "for labels in train_labels_tokenize['input_ids']:\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i]==tokenizer.pad_token_id:\n",
    "            labels[i] = -100\n",
    "\n",
    "print(train_inputs_tokenize['input_ids'].size())\n",
    "print(train_labels_tokenize['input_ids'].size())\n",
    "\n",
    "torch.save(train_inputs_tokenize, '/home/intern/seungjun/error_data/bart/training_input.pkl')\n",
    "torch.save(train_labels_tokenize, '/home/intern/seungjun/error_data/bart/training_label.pkl')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3016, 90])\n",
      "torch.Size([3016, 87])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "test_inputs_tokenize = tokenizer(test_input, return_tensors='pt', padding=True)\n",
    "test_labels_tokenize = tokenizer(test_label, return_tensors='pt', padding=True)\n",
    "\n",
    "for labels in test_labels_tokenize['input_ids']:\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i]==tokenizer.pad_token_id:\n",
    "            labels[i] = -100\n",
    "\n",
    "\n",
    "\n",
    "torch.save(test_inputs_tokenize, '/home/intern/seungjun/error_data/bart/evaluating_input.pkl')\n",
    "torch.save(test_labels_tokenize, '/home/intern/seungjun/error_data/bart/evaluating_label.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "print(test_inputs_tokenize['input_ids'][10])\n",
    "print(test_labels_tokenize['input_ids'][0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([    0, 28526,  3916,    35,  4337,   621,   782,     7,   216,    10,\n",
      "          828,    59, 10638,  2156, 17874,  2156,  5444,  2156, 13144,     8,\n",
      "          750,    11,   645,     7,  1413,    66,    11,  2313,   479,     2,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1])\n",
      "tensor([   0, 4030,  806,   34,   57, 2942,    7, 2313,  479,    2, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').to('cuda')\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "def training_bart(batch_size):\n",
    "    total_train_loss =0\n",
    "    train_inputs_tokenize = torch.load('/home/intern/seungjun/error_data/bart/training_input.pkl')\n",
    "    train_labels_tokenize = torch.load('/home/intern/seungjun/error_data/bart/training_label.pkl')\n",
    "    k=0\n",
    "    for iter in tqdm(range(len(train_inputs_tokenize['input_ids'])//batch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        temp_input_list1 = train_inputs_tokenize['input_ids'][iter*batch_size:(iter+1)*batch_size].to('cuda')\n",
    "        temp_input_list2 = train_inputs_tokenize['attention_mask'][iter*batch_size:(iter+1)*batch_size].to('cuda')\n",
    "        temp_label_list = train_labels_tokenize['input_ids'][iter*batch_size:(iter+1)*batch_size].to('cuda')  \n",
    "        temp = model(temp_input_list1,temp_input_list2, labels=temp_label_list)\n",
    "        total_train_loss +=temp.loss.item()\n",
    "        if(k%100==0 and k!=0):\n",
    "            print(\"loss: \", temp.loss.item())\n",
    "            print(\"loss average: \", total_train_loss/100)\n",
    "            total_train_loss =0\n",
    "        temp.loss.backward()\n",
    "        optimizer.step()     \n",
    "        k+=1\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    training_bart(5)\n",
    "    model.save_pretrained('/home/intern/seungjun/error_model/bartcond_'+str(epoch))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 17%|█▋        | 101/603 [00:13<01:04,  7.74it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.34295767545700073\n",
      "loss average:  0.8015401601791382\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 33%|███▎      | 201/603 [00:26<00:49,  8.09it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.868419885635376\n",
      "loss average:  0.6400506694614887\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 50%|████▉     | 301/603 [00:38<00:37,  8.05it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.32431620359420776\n",
      "loss average:  0.6383126907050609\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 67%|██████▋   | 401/603 [00:51<00:24,  8.11it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.5541464686393738\n",
      "loss average:  0.6306009389460087\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 83%|████████▎ | 501/603 [01:03<00:12,  8.05it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.2577066421508789\n",
      "loss average:  0.5507046036422253\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█████████▉| 601/603 [01:15<00:00,  8.07it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.33404016494750977\n",
      "loss average:  0.5667156411707401\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 603/603 [01:16<00:00,  7.92it/s]\n",
      " 17%|█▋        | 101/603 [00:12<01:02,  8.04it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.24237720668315887\n",
      "loss average:  0.455067693144083\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 33%|███▎      | 201/603 [00:24<00:49,  8.05it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.5708217024803162\n",
      "loss average:  0.3966701653599739\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 50%|████▉     | 301/603 [00:37<00:37,  8.01it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.26336970925331116\n",
      "loss average:  0.3949640330672264\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 67%|██████▋   | 401/603 [00:50<00:25,  7.98it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.43303218483924866\n",
      "loss average:  0.3960045565664768\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 83%|████████▎ | 501/603 [01:02<00:12,  7.95it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.2458404004573822\n",
      "loss average:  0.34412159107625484\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█████████▉| 601/603 [01:15<00:00,  7.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.1541789323091507\n",
      "loss average:  0.3616959162056446\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 603/603 [01:15<00:00,  8.00it/s]\n",
      " 17%|█▋        | 101/603 [00:12<01:02,  8.04it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.20110754668712616\n",
      "loss average:  0.3380600892007351\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 33%|███▎      | 201/603 [00:24<00:50,  8.03it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.4108854830265045\n",
      "loss average:  0.3236676996946335\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 50%|████▉     | 301/603 [00:37<00:37,  8.04it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.19128715991973877\n",
      "loss average:  0.3117509812116623\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 67%|██████▋   | 401/603 [00:49<00:25,  7.88it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.36095333099365234\n",
      "loss average:  0.3258049230277538\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 83%|████████▎ | 501/603 [01:02<00:12,  7.85it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.22760964930057526\n",
      "loss average:  0.2953510041534901\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█████████▉| 601/603 [01:15<00:00,  7.83it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.16370919346809387\n",
      "loss average:  0.30793945789337157\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 603/603 [01:15<00:00,  7.97it/s]\n",
      " 17%|█▋        | 101/603 [00:12<01:03,  7.93it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.20753155648708344\n",
      "loss average:  0.3111125862598419\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 33%|███▎      | 201/603 [00:25<00:50,  7.93it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.4806273877620697\n",
      "loss average:  0.3043927288800478\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 50%|████▉     | 301/603 [00:38<00:37,  8.05it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.20833314955234528\n",
      "loss average:  0.2960427372902632\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 67%|██████▋   | 401/603 [00:50<00:25,  7.97it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.22081129252910614\n",
      "loss average:  0.30542858600616457\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 83%|████████▎ | 501/603 [01:03<00:12,  8.04it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.24063222110271454\n",
      "loss average:  0.25786371521651746\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█████████▉| 601/603 [01:15<00:00,  7.77it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.1143263503909111\n",
      "loss average:  0.2739130436629057\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 603/603 [01:16<00:00,  7.93it/s]\n",
      " 17%|█▋        | 101/603 [00:12<01:02,  8.04it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.25539660453796387\n",
      "loss average:  0.2876864881813526\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 33%|███▎      | 201/603 [00:25<00:50,  7.96it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.3280859589576721\n",
      "loss average:  0.2710530141741037\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 50%|████▉     | 301/603 [00:37<00:37,  8.04it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.16209374368190765\n",
      "loss average:  0.2639503215253353\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 67%|██████▋   | 401/603 [00:50<00:25,  7.97it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.201626718044281\n",
      "loss average:  0.25984932646155356\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 83%|████████▎ | 501/603 [01:02<00:12,  8.05it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.20434334874153137\n",
      "loss average:  0.23671324051916598\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█████████▉| 601/603 [01:15<00:00,  8.06it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.11142513155937195\n",
      "loss average:  0.2452688653022051\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 603/603 [01:15<00:00,  8.00it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "model = BartForConditionalGeneration.from_pretrained('/home/intern/seungjun/error_model/bartcond_4').to('cuda')\n",
    "\n",
    "def ErrorSolution(input_string):\n",
    "    tokenized_input = tokenizer([input_string], return_tensors='pt').to('cuda')\n",
    "    summary_ids = model.generate(tokenized_input['input_ids'], num_beams = 32)\n",
    "\n",
    "    result_arr =[]\n",
    "    result = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "    result_arr.extend(result)\n",
    "\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "model = BartForConditionalGeneration.from_pretrained('/home/intern/seungjun/error_model/bartcond_4').to('cuda')\n",
    "\n",
    "def ErrorSolution_bart(input_string):\n",
    "    tokenized_input = tokenizer([input_string], return_tensors='pt').to('cuda')\n",
    "    summary_ids = model.generate(tokenized_input['input_ids'], num_beams = 32, max_length = tokenized_input['input_ids'].size()[1]+10)\n",
    "\n",
    "    result_arr =[]\n",
    "    result = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "    result_arr.extend(result)\n",
    "\n",
    "    return result\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "ErrorSolution_bart(\" One person if do n't have good health that means so many things they could lost .\")\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[\"If a person does n't have good health , that means they could lose so many things they could never have gotten rid of .\"]"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "model = BartForConditionalGeneration.from_pretrained('/home/intern/seungjun/error_model/bartcond_4').to('cuda')\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "def evaluating_bart(batch_size):\n",
    "    total_eval_loss =0\n",
    "    eval_inputs_tokenize = torch.load('/home/intern/seungjun/error_data/bart/evaluating_input.pkl')\n",
    "    eval_labels_tokenize = torch.load('/home/intern/seungjun/error_data/bart/evaluating_label.pkl')\n",
    "    k=0\n",
    "    for iter in tqdm(range(len(eval_inputs_tokenize['input_ids'])//batch_size)):\n",
    "        temp_input_list1 = eval_inputs_tokenize['input_ids'][iter*batch_size:(iter+1)*batch_size].to('cuda')\n",
    "        temp_input_list2 = eval_inputs_tokenize['attention_mask'][iter*batch_size:(iter+1)*batch_size].to('cuda')\n",
    "        temp_label_list = eval_labels_tokenize['input_ids'][iter*batch_size:(iter+1)*batch_size].to('cuda')\n",
    "        with torch.no_grad():  \n",
    "            temp = model(temp_input_list1,temp_input_list2, labels=temp_label_list)\n",
    "            loss = temp.loss\n",
    "        total_eval_loss +=loss.item()\n",
    "\n",
    "    avg_loss = total_eval_loss/ (len(eval_inputs_tokenize['input_ids'])//batch_size)\n",
    "    print(\" Validation Loss: {0:.2f}\".format(avg_loss))\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "evaluating_bart(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 597/597 [00:15<00:00, 39.59it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Validation Loss: 0.61\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('seungjun': conda)"
  },
  "interpreter": {
   "hash": "341a64a73c71f72c73c43a5871309cda6749634f7d74501be19d508023bea49b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}